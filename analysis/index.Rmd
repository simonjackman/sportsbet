---
title: "Betting odds and the 2022 Australian election"
author: "Professor Simon Jackman"
date: "`r format(Sys.time(), '%e %B %Y')`"
output:
  bookdown::html_document2:
    css: preamble.css
    toc: yes
    toc_float: yes  
    self-contained: true
fontsize: 11pt
link-citations: no
affiliation: University of Sydney
bibliography: betting.bib
editor_options:
  markdown:
    wrap: 80
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE,warnings=FALSE,message = FALSE)
options(htmltools.dir.version = FALSE)
options(knitr.kable.NA = '-')

library(tidyverse)
library(here)
library(fst)
library(r2d3)
options(r2d3.shadow=FALSE)
library(DT)
theStates <- c("ACT","NT","QLD","NSW","VIC","TAS","SA","WA")

library(scales)
beta_trans <- function(shape1=1/3,shape2=1/3,...){
  probability_trans("beta",shape1,shape2,...)}
```


```{r read-data-files,warning=FALSE,message=FALSE,error=FALSE}
theFiles <- list.files(here("data"),pattern="fst$",full.names = TRUE)
d <- lapply(theFiles,read.fst)
d <- bind_rows(d) %>% mutate(event=str_squish(event))
lubridate::tz(d$datetime) <- "Australia/Sydney"

## correct spelling error by Sportsbet
d <- d %>%
  mutate(event = ifelse(event=="Capriconia (QLD)","Capricornia (QLD)",event))

## catch any missing prices
d <- d %>%
  group_by(event,datetime) %>%
  mutate(prob = (1/prices)/sum(1/prices,na.rm=TRUE)) %>%
  ungroup()

lastDate <- str_squish(strftime(max(d$datetime),"%l%p %A %e %B"))

currentSeats <- d %>% 
  filter(lab %in% theStates) %>% 
  filter(as.Date(datetime,tz="Australia/Sydney") == Sys.Date()) %>% 
  distinct(event) %>%
  nrow()

## AEC results
load(here("data/aec_historic_2022.RData"))
incumbent_party <- aec_historic_2022 %>%
  filter(type=="tcp") %>%
  rename(outcomes=PartyAb,Division=DivisionName) %>%
  mutate(outcomes_collapsed = case_when(
    outcomes %in% c("LNP","LP","CLP","NP") ~ "LNP",
    outcomes=="GRN" ~ "GRN",
    outcomes=="IND" ~ "IND",
    outcomes=="ALP" ~ "ALP",
    TRUE ~ "OTH")
  ) %>%
  group_by(State,Division) %>%
  summarise(inc=outcomes_collapsed[which.max(p)]) %>%
  ungroup()

## NATIONAL MARKET
tab <- d %>% 
  filter(grepl(lab,pattern="Next Sworn")) %>% 
    filter(datetime==max(datetime)) %>%
  mutate(prob=prob*100) %>%
  mutate(prob_nls = ifelse(prob>10,prob,0),
         prob_nls = prob_nls/sum(prob_nls,na.rm=TRUE)*100) %>%
  mutate(prices = sprintf(prices,fmt="%4.2f")) %>%
  select(Result=outcomes,Price=prices,`IPOW`=prob,prob_nls)

alp_win_prob_nls <- tab$IPOW[tab$Result=="Labor"]/sum(tab$IPOW[1:2])*100

parse_outcomes <- function(outcomes){
  z <- gsub(outcomes,pattern="^.*\\((.*)\\)$",replacement = "\\1")
  z <- str_squish(z)
  z <- case_when(
    z == "Labor" ~ "ALP",
    z %in% c("Liberal","National","Liberal National","Liberal Party",
             "Nationals","Liberal National Party",
             "Country Liberal","The Nationals",
             "Coalition") ~ "LNP",
    z == "Greens" ~ "GRN",
    z == "Independent" ~ "IND",
    z == "One Nation" ~ "PHON",
    z == "United Australia Party" ~ "UAP",
    TRUE ~ "OTH"
  )
  return(z)
}

## HOUSE MARKETS, SUMMARY
now <- Sys.time()
yesterday <- now - 24*3600
dsum <- d %>%
  filter(lab %in% theStates) %>%
  group_by(event) %>%
  filter(datetime==max(datetime)) %>% ## most recent price for each seat
  ungroup() %>%
  mutate(event = str_squish(str_remove(event,pattern="\\([A-Z]{1,}\\).*$"))) %>%
  mutate(outcomes_collapsed = parse_outcomes(outcomes))

s <- dsum %>%
  group_by(event,outcomes_collapsed) %>%
  summarise(prob = max(prob,na.rm=TRUE)) %>%   ## take the leading candidate in a group, where multiples (e.g., multiple IND)
  ungroup() %>%
  mutate(prob = if_else(is.infinite(prob),0,prob)) %>%
  group_by(event) %>%
  mutate(prob_nls = ifelse(prob<.10,0,prob),
         prob_nls = prob_nls/sum(prob_nls,na.rm=TRUE)) %>%
  ungroup() 

s1 <- s %>%
  group_by(outcomes_collapsed) %>%
  summarise(`Expected Seats`=sum(prob,na.rm=TRUE),
            `Expected Seats (no long-shots)` = sum(prob_nls,na.rm=TRUE)) %>%
  ungroup() %>%
  rename(Party = outcomes_collapsed) %>%
  arrange(Party)

s2 <- s %>% 
  group_by(event) %>% 
  mutate(leader = prob_nls==max(prob_nls,na.rm=TRUE)) %>%
  ungroup() %>%
  mutate(leader=replace_na(leader,FALSE)) %>%
  group_by(event) %>%
  mutate(leader = leader/sum(leader,na.rm=TRUE)) %>%
  ungroup() %>%
  group_by(outcomes_collapsed) %>%
  summarise(n=sum(leader,na.rm=TRUE)) %>%
  ungroup() %>%
  rename(Party = outcomes_collapsed,Leads=n) %>%
  arrange(Party) 

s <- left_join(s1,
               s2,
               by="Party") %>%
  left_join(incumbent_party %>%
              count(inc) %>%
              rename(Party=inc,n_current=n),
            by="Party") %>%
  mutate(delta = Leads-n_current,
         delta = str_remove(as.character(delta),'\\.0{1,}$'),
         delta = ifelse(delta>0,
                        paste("+",delta,sep=""),
                        delta),
         Leads = str_remove(as.character(Leads),'\\.0{1,}$')
         )
         
h <- aec_historic_2022 %>%
  filter(!is.na(PartyAb)) %>%
  rename(outcomes=PartyAb,Division=DivisionName) %>%
  mutate(outcomes_collapsed = case_when(
    outcomes %in% c("LNP","LP","CLP","NP") ~ "LNP",
    outcomes=="GRN" ~ "GRN",
    outcomes=="IND" ~ "IND",
    outcomes=="ALP" ~ "ALP",
    TRUE ~ "OTH")
  ) %>%
  group_by(State,Division,type,outcomes_collapsed) %>%
  summarise(Votes = sum(Votes)) %>%
  ungroup() %>%
  group_by(State,Division,type) %>%
  mutate(p=Votes/sum(Votes)) %>%
  ungroup()

plotData <- left_join(h,
                      d %>%
                        filter(lab %in% theStates) %>%
                        group_by(event) %>%
                        filter(datetime==max(datetime)) %>%
                        ungroup() %>%
                        mutate(event = str_squish(str_remove(event,pattern="\\([A-Z]{1,}\\).*$"))) %>%
                        mutate(outcomes_collapsed = parse_outcomes(outcomes)) %>% 
                        mutate(prob_nls = ifelse(prob<.10,0,prob)) %>%
                        group_by(lab,event,outcomes_collapsed) %>%
                        summarise(prob_nls = sum(prob_nls,na.rm=TRUE),
                                  prices=min(prices,na.rm=TRUE)) %>%
                        ungroup() %>%
                        group_by(event) %>%
                        mutate(prob_nls = prob_nls/sum(prob_nls,na.rm=TRUE)*100) %>%
                        ungroup() %>%
                        rename(prob=prob_nls,State=lab,Division=event),
                      by=c("State","Division","outcomes_collapsed")
                      )

tmp <- plotData %>% 
  filter(type=="tcp" & outcomes_collapsed %in% c("ALP","LNP")) %>%
  mutate(votes=p*100)
save("tmp",file=here("data/linkedScatter.RData"))

tab_change <- plotData %>% 
  filter(type=="first_prefs") %>% 
  left_join(plotData %>%
              filter(type=="tcp") %>%
              select(State,Division,outcomes_collapsed,p),
              by=c("State","Division","outcomes_collapsed"),
            suffix = c("","_tcp")
            ) %>%
  mutate(p=replace_na(p,0),
         prob=replace_na(prob,0)) %>%
  group_by(Division) %>% 
  summarise(inc_indx = which.max(p_tcp),
            incumbent = outcomes_collapsed[inc_indx],
            incumbent_tcp = p_tcp[inc_indx],
            incumbent_prob = prob[inc_indx],
            incumbent_fav = sum(prob >= incumbent_prob)==1,
            favorite = outcomes_collapsed[which.max(prob)]) %>% 
  ungroup()

tab_change <- left_join(
  tab_change %>% 
    filter(!incumbent_fav),
  plotData %>% 
    select(Division,State) %>% 
    distinct(),
  by="Division") %>%
  arrange(incumbent_prob)


ind_leads <- dsum %>% 
    group_by(event) %>% 
    summarise(ok = "IND" %in% outcomes_collapsed[prob==max(prob)]) %>% 
    ungroup() %>% filter(ok) %>% pull(event)
```


```{r linkedScatter}
load(here("data/linkedScatter.RData"))

if(!file.exists(here("js/d3-tip.js"))){
  download.file("https://cdn.jsdelivr.net/gh/bumbeishvili/d3-tip-for-v6@4/d3-tip.min.js", 
                here("js/d3-tip.js"))
}

ld_50_objective <- function(object,x){
  yhat <- predict(object,newdata=data.frame(votes=x),type="response")
  return(50-yhat)
}

ld_50_finder <- function(m){
  uniroot(ld_50_objective,interval=c(40,60),object=m)$root  
}

library(mgcv)
library(modelr)
m <- tmp %>%
  group_by(outcomes_collapsed) %>%
  nest() %>%
  mutate(m=map(data,~gam(prob ~ s(votes),data=.x)),
         yhat=map2(.x=data,
                   .y=m,
                   ~add_predictions(data=data.frame(votes=seq_range(.x$votes,by=.10)),
                                    model=.y,
                                    type="response")
         ),
         ld50=map2(.x=data,.y=m,~ld_50_finder(.y))
  )

yhat <- m %>%
  unnest(yhat) %>%
  ungroup() %>%
  select(outcomes_collapsed,votes,pred) %>%
  mutate(votes=as.numeric(votes),
         pred=as.numeric(pred)) %>%
  mutate(pred = ifelse(pred<0,0,pred),
         pred = ifelse(pred>100,100,pred))


data_for_d3 <- list(data=tmp %>% mutate(across(where(is.double),as.numeric)) %>% 
                      select(Division,State,votes,prob,prices,outcomes_collapsed) %>%
                      mutate(i = match(Division,sort(unique(Division)))) %>%
                      as.data.frame(),
                    yhat=yhat)

ld50 <- m %>% unnest(ld50) %>% select(outcomes_collapsed,ld50)
```

<br>

# Summary

::: {#summary .highlights}
As of `r lastDate`, Sportsbet betting odds imply:

- `r ifelse(alp_win_prob_nls>50,"Labor","Coalition")` to form the next government with 
`r round(max(c(alp_win_prob_nls,100-alp_win_prob_nls)),1)`% probability.

- `r nrow(tab_change)` House of Representatives seats are priced as changing hands; see section \@ref(seats-changing-hands) below. 

- Independents favourites or equal favourites in `r length(ind_leads)` seats: `r knitr::combine_words(ind_leads)`.

- Current Sportsbet prices are consistent with a `r round(ld50$ld50[ld50$outcomes_collapsed=="LNP"] - 50,1)` percentage point TCP swing from the Coalition to Labor; see \@ref(ipow-rship) below.
:::

This analysis examines Sportsbet odds in various election betting markets for the
2022 Australian federal election.

We convert odds into *implied probabilities of winning* (IPOW) using a procedure
explained in the Appendix.

In the tables and charts below, we express IPOWs as percentages.   Long shots (IPOWS < 10%) are set to zero and the remaining IPOWs re-normalised to sum to 100%.

<br>

# Next government market

As of `r lastDate`:

```{r next-government-market}
knitr::kable(tab,
             digits=c(0,2,1,1),
             align=c("l","r","r","r"),
             col.names = c("Result","Price","IPOW","IPOW<br>(no long shots)"))
```

Time series:
```{r time-series}
library(highcharter)
hdata <- d %>% 
  filter(grepl(lab,pattern="Next Sworn")) %>%
  mutate(prob=prob*100) %>%
  mutate(prob_nls = ifelse(prob>10,prob,0)) %>%
  group_by(datetime) %>%
  mutate(prob_nls = prob_nls/sum(prob_nls)*100) %>%
  ungroup() %>%
  filter(outcomes!="Any Other")

hc <- 
  # highchart(hc_opts=list(time=list(timezone="Australia/Sydney",useUTC=FALSE)),
  #               width=900,height=650) %>%
  # hc_add_series_list(split(hdata,hdata$outcomes)) %>%
  hchart(as.data.frame(hdata),
       hcaes(x = datetime_to_timestamp(datetime),
             y = prob_nls,
             group=outcomes),
       type="line") %>%
  hc_xAxis(title=list(text=""),type="datetime",
           dateTimeLabelFormats=list("day"="%e %b")) %>%
  hc_colors(colors=c("#009de3","#ed1b35")) %>%
  hc_yAxis(title=list(text="IPOW")) %>%
  hc_tooltip(valueDecimals=1,
             valueSuffix="%",
             xDateFormat="%l%p %A %e %b",  ## %A works but %a gives UTC (I think), weird bug in highcharts 
             dateTimeLabelFormats=list("day"="%e %b")) %>%
  hc_plotOptions(line=list(step="center",marker=list(symbol="circle"))) %>% 
  hc_size(width=840)

## trying to coerce things to local time zone
hc$x$conf_opts$global$useUTC <- FALSE
hc$x$conf_opts$global$timezone <- "Australia/Sydney"
hc$x$conf_opts$global$timezoneOffset <- -10*60
hc$x$hc_opts$plotOptions$time <- list(timezone="Australia/Sydney",
                                      useUTC=FALSE,
                                      timezoneOffset=-10*60)
hc
```

<br>

# House of Representatives seats

## Expected seat counts

We compute expected seat counts by summing the seat-specific probabilities of
winning implied by Sportsbet's odds as at `r lastDate`.   



```{r house-summary}

knitr::kable(s,digits=1,
             align=rep("r",dim(s)[2]),
             col.names = c("Party",
                           "Expected<br>Seats",
                           "Expected<br>Seats<br>(no long-shots)",
                           "Seats<br>where<br>favourite",
                           "Current<br>Seats",
                           "âˆ† seats"))
```

**Notes on table:** the second column of seat counts removes "long-shots"; the third column counts seats where the indicated party has the highest
IPOW (tied leads are split proportionately among equal favourites); "Current Seats" is the count of each party current seats (won in 2019 or notional after redistributions etc); $\Delta$ is the implied gain or loss in seat totals for each party, based on the current betting market front-runner in each seat.

<br>


<br>

## Seat-by-seat IPOWs 

```{r seat-by-seat-ipows}
tab <- d %>%
  filter(lab %in% theStates) %>%
  group_by(event) %>%
  filter(datetime==max(datetime)) %>%
  ungroup() %>%
  mutate(event = str_remove(event,pattern="\\([A-Z]{1,}\\).*$")) %>%
  mutate(outcomes_collapsed = parse_outcomes(outcomes)) %>%
  mutate(event=str_squish(event),
         outcomes_collapsed = str_squish(outcomes_collapsed)) %>%
  group_by(lab,event,datetime,outcomes_collapsed) %>%
  summarise(prob = max(prob,na.rm=TRUE)) %>%   ## get single biggest prob for a cand, hack for the case of multiple IND/OTH
  ungroup() %>%
  group_by(lab,event,datetime) %>%
  mutate(prob_nls = ifelse(prob<.10,0,prob),
         prob_nls = prob_nls/sum(prob_nls,na.rm=TRUE)*100,
         prob=prob_nls,
         prob = replace_na(prob,0)) %>%
  ungroup() %>%
  pivot_wider(id_cols=c("lab","event","datetime"),
              names_from = "outcomes_collapsed",
              values_from = "prob")

datatable(tab %>% 
            mutate(datetime = str_squish(strftime(datetime,"%l%p %a %e %b"))),
          rownames=FALSE,
          colnames=c('State'="lab","Division"="event","Last seen"="datetime"),
          options=list(order=list(list(5,'desc')),
                       columnDefs=list(list(className = 'dt-left', targets=c(0,1,2)))),
          caption = "Probability of Winning implied by Sportsbet prices (long shots removed)")  %>%
  formatRound(columns=c('ALP','LNP','GRN',"IND","PHON","UAP","OTH"),1)
```

## Seats tipped to change hands {#seats-changing-hands}

The following `r nrow(tab_change)` seats do **not** have the candidate of the incumbent party as the unique market favourite:

```{r seats-changing-hands,results='asis'}
datatable(tab_change %>%
            mutate(incumbent_tcp=100*incumbent_tcp) %>%
            select(Division,State,
                   Incumbent=incumbent,
                   `Incumbent TCP`=incumbent_tcp,
                   `Incumbent IPOW`=incumbent_prob,
                   Favourite=favorite),
          rownames = FALSE,
          options=list(style="bootstrap4",
                       pageLength=nrow(tab_change),
                       dom="t",
                       columnDefs=list(list(className = 'dt-left', targets=c(0,1)),
                                       list(className = 'dt-center', targets=c(2,3,4,5))
                       )
          ),
          caption = "") %>%
  formatRound(columns=c(4,5),digits=1)
```

## Relationship between IPOW and seat margins {#ipow-rship}

With long-shot probabilities again set to zero, we examine the relationship between IPOWs and two-candidate preferred results in each seat, using 2019 results or notional results in the event of electoral redistributions since 2019.

Current Sportsbet prices are broadly consistent with the assumption of a `r round(ld50$ld50[ld50$outcomes_collapsed=="LNP"] - 50,1)` percentage point TCP swing from the Coalition to Labor.  

The blue line is a smoothing spline.

Roll a mouse or pointing device over individual data points for more information.   

```{r js-linkedscatter}
library(jsonlite)
r2d3(data=toJSON(data_for_d3,
                 dataframe = "rows", auto_unbox = FALSE),
     viewer="browser",
     width = 840,
     height=400,
     container="div",
     dependencies = here("js/d3-tip.js"),
     elementId="linkedScatter",
     script=here("js/linkedScatter.js"))
```

## Fluctuations

```{r daily}
## last 24 hours of data
h_fluc_24 <- d %>%
    filter(lab %in% theStates) %>%
  mutate(outcomes_collapsed = 
           if_else(
             grepl(outcomes,pattern=")$"),
             parse_outcomes(outcomes),
             case_when(
               outcomes=="Coalition" ~ "LNP",
               outcomes=="Green" ~ "GRN",
               outcomes=="Labor" ~ "ALP",
               outcomes=="One Nation" ~ "PHON",
               outcomes=="United Australia Party" ~ "UAP",
               grepl(outcomes,pattern="Indep") ~ "IND",
               TRUE ~ "OTH")
           )
  ) %>%
  mutate(event = str_remove(event,pattern="\\([A-Z]{1,}\\).*$")) %>%
  group_by(event) %>%
  arrange(desc(datetime)) %>%
  filter(datetime>(Sys.time()-25*3600)) %>%
  ungroup() %>%
  group_by(event,datetime) %>%
  mutate(prob_nls = ifelse(prob<.10,0,prob)) %>%
  mutate(prob_nls = prob_nls/sum(prob_nls,na.rm=TRUE)) %>%
  ungroup() %>%
  mutate(prob_nls = replace_na(prob_nls,0)) %>%
  arrange(event,outcomes_collapsed,datetime)

h_fluc_24 <- h_fluc_24 %>%
  semi_join(h_fluc_24 %>%
              group_by(event,outcomes) %>%
              summarise(flag = (max(prob_nls,na.rm=TRUE)-min(prob_nls,na.rm=TRUE)) > .Machine$double.eps) %>%
              ungroup() %>%
              group_by(event) %>%
              summarise(flag=any(flag)) %>%
              ungroup() %>%
              filter(flag) %>%
              distinct(event),
            by="event"
  )

# h_fluc_24 <- h_fluc_24 %>%
#     semi_join(h_fluc_24 %>%
#                 group_by(event,outcomes) %>%
#                 summarise(all_zero = all(prob_nls==0)) %>%
#                 ungroup() %>%
#                 filter(all_zero),
#               by=c("event","outcomes"))

if(nrow(h_fluc_24)>0){
  tab <- h_fluc_24 %>%
    mutate(event=str_squish(event),
           outcomes_collapsed = str_squish(outcomes_collapsed)) %>%
    mutate(prob=prob_nls) %>%
    group_by(lab,event,datetime,outcomes_collapsed) %>%
    summarise(prob = sum(prob,na.rm=TRUE)*100) %>%
    ungroup() %>%
    mutate(prob = replace_na(prob,0)) %>%
    pivot_wider(id_cols=c("lab","event","datetime"),
                names_from = outcomes_collapsed,
                values_from = prob) %>%
    group_by(lab,event) %>%
    arrange(datetime) %>%
    mutate(delta=ALP!=lag(ALP) | GRN!=lag(GRN) | LNP !=lag(LNP) | IND !=lag(IND)) %>%
    ungroup() %>%
    group_by(lab,event) %>%
    slice(c(which.max(delta)-1,which(delta))) %>%
    ungroup() %>%
    select(-delta) %>%
    arrange(event,datetime)
} else {
  tab <- NULL
}

h_fluc_24_nseats <- n_distinct(tab$event)
h_fluc_24_label <- paste(h_fluc_24_nseats,ifelse(h_fluc_24_nseats==1,"seat","seats"),sep=" ")
```

### `r h_fluc_24_label` with odds changing in the last 24 hours {.unnumbered}

```{r eval=h_fluc_24_nseats>0}
datatable(tab %>% 
            mutate(datetime = str_squish(strftime(tab$datetime,"%l%p %a %e %b"))),
          rownames=FALSE,
          colnames=c('State'="lab","Division"="event","Seen"="datetime"),
          extensions = "RowGroup",
          options=list(rowGroup=list(dataSrc=1),
                       columnDefs=list(list(targets=c(0,1),visible=FALSE))
                       ),
          caption = "Probability of Winning implied by Sportsbet prices (long shots removed)")  %>%
  formatRound(columns=4:ncol(tab),1)
```


```{r week}
h_fluc_week <- d %>%
  filter(lab %in% theStates) %>%
   mutate(outcomes_collapsed = 
           if_else(
             grepl(outcomes,pattern=")$"),
             parse_outcomes(outcomes),
             case_when(
               outcomes=="Coalition" ~ "LNP",
               outcomes=="Green" ~ "GRN",
               outcomes=="Labor" ~ "ALP",
               outcomes=="One Nation" ~ "PHON",
               outcomes=="United Australia Party" ~ "UAP",
               grepl(outcomes,pattern="Indep") ~ "IND",
               TRUE ~ "OTH")
           )
  ) %>%
  group_by(event) %>%
  arrange(desc(datetime)) %>%
  filter(as.Date(datetime,tz="Australia/Sydney")>(Sys.Date()-8)) %>%
  ungroup() %>%
  group_by(event,datetime,outcomes_collapsed) %>%
  summarise(prob=sum(prob,na.rm=TRUE)) %>%
  ungroup() %>%
  group_by(event,datetime) %>%
  mutate(prob_nls = ifelse(prob<.10,0,prob)) %>%
  mutate(prob_nls = prob_nls/sum(prob_nls)) %>%
  ungroup() %>%
  arrange(event,outcomes_collapsed,datetime)

h_fluc_week <- h_fluc_week %>%
    anti_join(h_fluc_week %>%
                group_by(event,outcomes_collapsed) %>%
                summarise(all_zero = all(prob_nls==0),
                          all_na = all(is.na(prob_nls)),
                          all_inf=all(is.infinite(prob_nls))) %>%
                ungroup() %>%
                filter(all_zero | all_inf | all_na),
              by=c("event","outcomes_collapsed"))

h_fluc_week <- h_fluc_week %>%
  semi_join(h_fluc_week %>%
              group_by(event,outcomes_collapsed) %>%
              summarise(flag = max(prob_nls,na.rm=TRUE)!=min(prob_nls,na.rm=TRUE)) %>%
              ungroup() %>%
              filter(flag) %>%
              distinct(event),
            by="event"
  )

if(nrow(h_fluc_week)>0){
  h_fluc_week <- h_fluc_week %>%
    anti_join(h_fluc_week %>%
                group_by(event,outcomes_collapsed) %>%
                summarise(all_zero = all(prob_nls==0),
                          all_inf=all(is.infinite(prob_nls))) %>%
                ungroup() %>%
                filter(all_zero | all_inf),
              by=c("event","outcomes_collapsed"))
}
panels <- length(unique(h_fluc_week$event))
h_fluc_week_label <- paste(panels,ifelse(panels==1,"seat","seats"),sep=" ")
```

### `r h_fluc_week_label` with odds changing in the last week {.unnumbered}

```{r h-fluc-week-plot,fig.height=1.5*ceiling(panels/2),eval=panels>0}
g <- ggplot(h_fluc_week,
              aes(x=datetime,
                  y=prob_nls,
                  group=outcomes_collapsed,
                  col=outcomes_collapsed)) + 
    geom_step() + 
    scale_x_datetime("",minor_breaks = NULL,
                     timezone = "Australia/Sydney",
                     date_labels = "%e %b") + 
    scale_y_continuous("IPOW",
                       minor_breaks=NULL,
                       trans="beta",
                       breaks=c(0,.30,.4,.5,.6,.70,1),
                       labels = function(b){as.character(100*b)}) + 
    scale_color_manual("",values=c("LNP"="#009de3","ALP"="#ed1b35")) + 
    facet_wrap(~event,ncol = 2) + 
    theme_minimal(base_family = "Avenir") + 
    theme(legend.position = "bottom",legend.direction = "horizontal")

g
```


```{r h-fluc-month,fig.height=8,fig.width=8}
h_fluc_month <- d %>%
  filter(lab %in% theStates) %>%
   mutate(outcomes_collapsed = 
           if_else(
             grepl(outcomes,pattern=")$"),
             parse_outcomes(outcomes),
             case_when(
               outcomes=="Coalition" ~ "LNP",
               outcomes=="Green" ~ "GRN",
               outcomes=="Labor" ~ "ALP",
               outcomes=="One Nation" ~ "PHON",
               outcomes=="United Australia Party" ~ "UAP",
               grepl(outcomes,pattern="Indep") ~ "IND",
               TRUE ~ "OTH")
           )
  ) %>%
  group_by(event) %>%
  arrange(desc(datetime)) %>%
  filter(as.Date(datetime,tz="Australia/Sydney")>(Sys.Date()-28)) %>%
  ungroup() %>%
  group_by(event,datetime,outcomes_collapsed) %>%
  summarise(prob=sum(prob,na.rm=TRUE)) %>%
  ungroup() %>%
  group_by(event,datetime) %>%
  mutate(prob_nls = ifelse(prob<.10,0,prob)) %>%
  mutate(prob_nls = prob_nls/sum(prob_nls)) %>%
  ungroup() %>%
  arrange(event,outcomes_collapsed,datetime)

h_fluc_month <- h_fluc_month %>%
    anti_join(h_fluc_month %>%
                group_by(event,outcomes_collapsed) %>%
                summarise(all_zero = all(prob_nls==0),
                          all_na = all(is.na(prob_nls)),
                          all_inf=all(is.infinite(prob_nls))) %>%
                ungroup() %>%
                filter(all_zero | all_inf | all_na),
              by=c("event","outcomes_collapsed"))

h_fluc_month <- h_fluc_month %>%
  semi_join(h_fluc_month %>%
              group_by(event,outcomes_collapsed) %>%
              summarise(flag = max(prob_nls,na.rm=TRUE)!=min(prob_nls,na.rm=TRUE)) %>%
              ungroup() %>%
              filter(flag) %>%
              distinct(event),
            by="event"
  )

if(nrow(h_fluc_month)>0){
  h_fluc_month <- h_fluc_month %>%
    anti_join(h_fluc_month %>%
                group_by(event,outcomes_collapsed) %>%
                summarise(all_zero = all(prob_nls==0),
                          all_inf=all(is.infinite(prob_nls))) %>%
                ungroup() %>%
                filter(all_zero | all_inf),
              by=c("event","outcomes_collapsed"))
}
panels <- length(unique(h_fluc_month$event))
h_fluc_month_label <- paste(panels,ifelse(panels==1,"seat","seats"),sep=" ")
```

### `r h_fluc_month_label` with odds changing hands last 28 days {.unnumbered}

```{r make-fluc-month-plot,fig.height=1.5*ceiling(panels/2),eval=panels>0}
g <- ggplot(h_fluc_month,
            aes(x=datetime,y=prob_nls,
                group=outcomes_collapsed,
                col=outcomes_collapsed)) + 
  geom_step() + 
  scale_x_datetime("",minor_breaks = NULL,
                   timezone = "Australia/Sydney",
                   date_labels = "%e\n%b") + 
  scale_y_continuous("IPOW",
                     minor_breaks=NULL,
                     trans="beta",
                     breaks=c(0,.30,.4,.5,.6,.70,1),
                     labels = function(b){as.character(100*b)}) + 
  scale_color_manual("",values=c("LNP"="#009de3","ALP"="#ed1b35")) + 
  facet_wrap(~event,ncol = 2) + 
  theme_minimal(base_family = "Avenir") + 
  theme(legend.position = "bottom",legend.direction = "horizontal")

g
```


# Appendix

Australian bookmakers tend to use decimal odds, the return to the punter of a
successful unit or one-dollar wager. In general, the more likely the event, the
closer the decimals odds approach 1.00 from above; conversely, the less likely
the event, decimal odds take on increasingly larger values.

If $d = (d_1, \ldots, d_J)'$ are decimal odds over $J$ mutually exclusive and
exhaustive outcomes then the implied probability of event $j \in 1, \ldots, J$
is conventionally recovered as 

\begin{equation} 
  p_j = \frac{1/d_j}{\sum_{k=1}^J 1/d_k}
  (\#eq:normalisation)
\end{equation}

In the context of elections, we refer to $p_j$ as the *implied probability of
winning* or IPOW for party or candidate $j$.

This transformation of decimal odds into IPOWs can be rationalised as follows.
Bookmakers set prices not merely as a function of their beliefs about outcomes,
but also to lock in profits. The most telling case comes from observing that for
coin tosses ahead of cricket matches, bookmakers typically offer prices of $d$ =
1.91 or thereabouts for each of the two outcomes; more surprising is that
gamblers participate in this market at all. This is a case where the *actual*
probabilities held by both bookmakers and punters can be reasonably presumed to
be .5 for each of the two outcomes. A fair price on a unit wager is therefore
2.00, with expected value of 1.00 = .5 $\times$ 2.00 + .5 $\times$ 0.

Observe that the fair price of $d$ = 2.00 is simply the inverse of the
probability of $p$ = .5. This result generalises: fair decimal odds are simply
the inverse of the probabilities of the corresponding events, or $d = 1/p$ and
conversely $p = 1/d$.

But bookmakers prices can not be assumed to be fair. For the coin toss example,
the bookmakers' prices of *less* than the fair price of 2.00 reflect their
profit margin. With decimals odds of $d$ = 1.91, the bookmaker will lose 91
cents on each successful dollar wager, but keep \$1.00 on each unsuccessful
wager. This asymmetry in payouts with respect to equally likely events is the
key to the adage that "the house always wins". In this example the bookmaker has
an expected yield of 4.5c cents per dollar waged.

Alternatively, applying the rule that probabilities are the inverses of the
corresponding decimal odds, then with prices of 1.91 on both outcomes, the
bookmaker's apparent probabilities are 0.5236 for each outcome. This clearly
violates the law of total probability (that the probabilities over the set of
possible outcomes sum to one), in this case summing to 1.0471.

The apparent "extra probability" is known as the "over-round" or "vigorish".
Bookmakers prices therefore reflect at least two inputs: (1) probabilities about
events; (2) profit margins [@cortisExpectedValuesVariances2015]. Let $p_j$ be
the bookmakers' privately held probability of event $j$. A profit-motivated
bookmaker offers prices of $d_j = 1/\pi_j$, where $\pi_j = p_j(1+k_j)$ with
$k_j > 0$ the source of the bookmaker's profits.

In the literature assessing the predictive value of betting markets, the
conversion from decimal odds almost always assumes $k_j$ is a constant $k$ over
all events $j$, giving rise to the transformation

$$
\frac{1/d_j}{\sum_j 1/d_j} = \frac{\pi_j}{\sum_j \pi_j} = \frac{p_j(1+k)}{\sum_j p_j(1+k)} = \frac{(1+k)\, p_j}{(1+k)\sum_j p_j} = p_j,
$$ as per equation \@ref(eq:normalisation).

@strumbeljDeterminingProbabilityForecasts2014 and @levittWhyAreGambling2004
survey cases where $k_j$ might reasonably be expected to *not* be constant over
outcomes $j$; examples include information and skill asymmetries between
bookmakers and punters and/or bookmakers seeking to counter insider-trading.
Betting markets with large numbers of gamblers and bookmakers should generally
drive these effects towards zero, resulting in small variability in $k_j$ over
alternatives, validating the mapping from odds to IPOWs in equation
\@ref(eq:normalisation).

Of course, prior research suggests that seat-by-seat markets are thinly traded,
and so we interpret IPOWs in these markets with appropriate caveats. 
Following my earlier work [@jackmanAllThatGlitters2015], one of the goals of this
analysis in its post-election phase will be to assess the calibration of IPOWs
with election outcomes.

# References



